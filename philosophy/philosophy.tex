% This file is part of the Data Analysis Recipes project.
% Copyright 2012 David W. Hogg (NYU)

% style notes
% -----------
% - when at the end of the sentence, put the \endnote AFTER the period
% - when at the end of a phrase, put the \endnote BEFORE the comma or parens
% - make sure the endnotes can be read on their own, outside of context
% - careful with the words ``error'', ``uncertainty''
% - careful with the words ``probability'', ``frequency'', ``likelihood''
% - use () for function arguments, and [] for grouping/precedence
% - define macros; remember 1, 2, infinity
%   - (check out my awesome \given macro)
% - put new terms in \emph{}, put only referred-to words in quotation marks.
% - do in-text itemized lists with \textsl{(a)}~ and so on.

\documentclass[12pt,twoside]{article}
\usepackage{amssymb,amsmath,mathrsfs,../hogg_endnotes,natbib}
\usepackage{float,graphicx}

\setlength{\emergencystretch}{2em}%No overflow

\newcommand{\notenglish}[1]{\textsl{#1}}
\newcommand{\aposteriori}{\notenglish{a~posteriori}}
\newcommand{\apriori}{\notenglish{a~priori}}
\newcommand{\adhoc}{\notenglish{ad~hoc}}
\newcommand{\etal}{\notenglish{et al.}}

\newcommand{\documentname}{document}
\newcommand{\sectionname}{Section}
\newcommand{\equationname}{equation}
\newcommand{\figurenames}{\figurename s}
\newcommand{\problemname}{Exercise}
\newcommand{\problemnames}{\problemname s}
\newcommand{\solutionname}{Solution}
\newcommand{\notename}{note}

\newcommand{\note}[1]{\endnote{#1}}
\def\enotesize{\normalsize}
\renewcommand{\thefootnote}{\fnsymbol{footnote}} % the ONE footnote needs this

\newcounter{problem}
\newenvironment{problem}{\paragraph{\problemname~\theproblem:}\refstepcounter{problem}}{}
\newcommand{\affil}[1]{{\footnotesize\textsl{#1}}}

% matrix stuff
\newcommand{\mmatrix}[1]{\boldsymbol{#1}}
\newcommand{\inverse}[1]{{#1}^{-1}}
\newcommand{\transpose}[1]{{#1}^{\scriptscriptstyle \top}}
% parameter vectors
\newcommand{\parametervector}[1]{\mmatrix{#1}}
\newcommand{\pvtheta}{\parametervector{\theta}}
% set stuff
\newcommand{\setofall}[3]{\{{#1}\}_{{#2}}^{{#3}}}
\newcommand{\allq}{\setofall{q_i}{i=1}{N}}
% other random multiply used math symbols
\newcommand{\dd}{\mathrm{d}}
\newcommand{\given}{\,|\,}

% header stuff
\renewcommand{\MakeUppercase}[1]{#1}
\pagestyle{myheadings}
\renewcommand{\sectionmark}[1]{\markright{\thesection.~#1}}
\markboth{Frequentists and Bayesians}{}

\begin{document}
\thispagestyle{plain}\raggedbottom
\section*{DRAFT 2012-03-10:\ Data analysis recipes:\ \\
  Frequentists and Bayesians\footnotemark}

\footnotetext{%
  The \notename s begin on page~\pageref{note:first}, including the
  license\note{\label{note:first}%
    Copyright 2012 David W. Hogg (NYU).  You may copy and distribute this
    document provided that you make no changes to it whatsoever.}
  and the acknowledgements\note{%
    It is a pleasure to thank
      Kyle Cranmer (NYU),
      Dustin Lang (CMU), and
      Sam Roweis (deceased)
    for discussions and comments that shaped these ideas.  This
    research was partially supported by the US National Aeronautics
    and Space Administration and National Science Foundation.}}

\noindent
David~W.~Hogg\\
\affil{Center~for~Cosmology~and~Particle~Physics, Department~of~Physics, New York University}\\
\affil{Max-Planck-Institut f\"ur Astronomie, Heidelberg}
%% \\[1ex]
%% A. Nother Author
%% \affil{Center~for~Cosmology~and~Particle~Physics, Department~of~Physics, New York University}

\begin{abstract}
In performing an inference or a scientific investigation, the
frequentist and the Bayesian both must choose a set of models that
will be considered.  Each model consists of a method for calculating a
likelihood, or the probability (or frequency of occurrence in
hypothetical repeated experiments) of the data given the model and
it's parameters.  There is no disagreement at this point between the
frequentist and the Bayesian, provided that they are both
probabilistic reasoners.  The Bayesian, in addition, is willing to
place a measure on model space, and, within each model, on parameter
space.  This measure is the prior probability; it is an additional
assumption but permits the Bayesian to perform (often very valuable)
marginalizations over models or nuisance parameters.  When a definite
answer or decision is required, the Bayesian can optimize an
expectation of utility whereas the frequentist is forced to do
something more heuristic.  In short, there are no conflicts between
frequentists and Bayesians; frequentists make fewer assumptions and
Bayesians have greater capabilities.  I illustrate these points with
specific examples; I also review probability calculus for the rusty.
\end{abstract}

\noindent
What is my goal in writing this \documentname?  It is to put a wet
blanket on some of the fires burning in data analysis between
frequentists and Bayesians, because (of course) there is no conflict
between these groups.  Often there are seeming conflicts at
``punchline level'' between some kind of frequentist conclusion and
some kind of Bayesian conclusion.  However, when each case is
considered carefully, there can't be a conflict, because frequentist
and Bayesian analyses \emph{answer different questions}.  One answers
questions about how well models explain data, the other can also
answer questions about the relative plausibilities of the models, or
how to weight them when making new predictions.

Many punchline-level differences between frequentists and Bayesians
are phrased in terms of what each investigator would \emph{decide} in
a hypothetical data analysis situation.  However, if we are all
probabilistic reasoners---and this \documentname\ will assume that we
are---then we all agree that the data are noisy; the data \emph{never}
lead to a completely decisive result.  That is, data analysis does not
lead to decisions.  It might lead to information that is very useful
in making decisions, but \emph{decisions} are not the output of an
inference.  At the end of any experiment, the result is a set of
probabilities, probabilities of the data given each of the models and
at every setting of the parameters, and (for the Bayesian) also
posterior probabities---think of them as quantitative plausibilities
if you don't want to assume too much---for all those models and
settings.  What each investigator does with those probabilities is a
subject outside the provenance of probabilistic inference and inside
the area of decision theory.

In real situations, decisions often do have to be made, because the
data might be being analyzed in order to inform a business decision,
plan a new experiment, or choose objects or models for further study.
When decisions \emph{do} have to be made, the frequentist and the
Bayesian will in general make them differently, because the
frequentist is careful not to make unnecessary assumptions, while the
Bayesian has measures that permit integrals; I hope to address this at
least briefly towards the end of this \documentname.  However, any
decision-making process is pasted on to probabilistic inference after
the probabilistic part is over, so the difference between how
frequentists and Bayesians decide things is just a pure consequence of
the different questions they are permitted to ask and answer.

There is a kind of data-analyzer or scientific investigator that I
could describe who is undeniably worse than \emph{either} a
frequentist \emph{or} a Bayesian.  This is the kind of data analyzer
who makes up by magic or intuition a heuristic arithmetic operation to
perform on the data, and publishes, as her or his result, the outcome
of that heuristic operation.  This kind of investigator is not a
probabilistic reasoner (probability theory, after all, was not
referenced in the construction of the heuristic arithmetic operation).
The inferences of any such investigator will necessarily be improved
upon by either the frequentist or the Bayesian, at least as I will
define them below.  In this sense, anyone with a likelihood function
is a friend, relatively speaking, and if the frequentists and
Bayesians among us are planning on having a fight, it shouldn't be
with one another, it should be with these arithmetic-operators, who
have given a bad name to ``statistics''\note{I never use the word
  ``statistics'' in my research now; for me it conjures up the idea of
  ``computing a statistic'' on the data (yes, a heuristic arithmetic
  operation) and then comparing that statistic to the ``right answer''
  in a set of naively constructed sets of artificial data.} and
propagated wrong results throughout the literatures of so many fields.

\section{What is a model?}

\section{Likelihoods are forever.}

Note that the likelihood often contains sort-of two components, one of
which is sort-of the expectation value for the data, and one of which
is sort-of the noise model for the data.  The former is usually
dominated by the signals of interest, and the latter is usually
dominated by properties of the recording device.  None of this is
strictly true, but it is often true.

\section{Measure theory or probabilities.}

Formally, probability theory is extremely simple.  However, it is not
always part of a physicist's (or biologist's or chemist's or
economist's) education; so I am going to give a very fast review right
here.  The key idea I want to convey is that if you think about the
units or dimensions of the things you are using, you almost never go
wrong.

For space and specificity---and because it is most useful for most
problems I encounter---I will focus on continuous parameters rather
than binary, integer, or discrete parameters.  I also won't be
specific about the domain of variables (for example whether a variable
$a$ is defined on $0<a<1$ or $0<a<\infty$ or $-\infty<a<\infty$); the
limits of integrals will be implicit.\note{In my world, \emph{all
    integrals are definite integrals}.  The integral is never just the
  anti-derivative, it is always a definite, finite, area or volume or
  measure.}

Probability distribution functions have units or dimensions.  Don't
ignore them.  For example, if you have a continuous parameter $a$, and
a PDF $p(a)$ for $a$, it must obey the normalization condition
\begin{eqnarray}\displaystyle
1 &=& \int p(a)\,\dd a
\quad ,
\end{eqnarray}
where the limits of the integral should be thought of as going over
the entire domain of $a$.  This is almost the \emph{definition} of a
PDF, from my (pragmatic, informal) point of view.  This normalization
condition shows that $p(a)$ has units of $a^{-1}$.  Nothing else would
integrate properly to a dimensionless result.  Even if $a$ is a
multi-dimensional vector or list or tensor or field or even point in
function space, the PDF must have units of $a^{-1}$.  In the
multi-dimensional case, the units of $a^{-1}$ are found by taking the
product of all the units of all the dimensions.

Most problems we will encounter will have multiple parameters; even if
we \emph{condition} $p(a)$ on some particular value of another
parameter $b$, that is, ask for the PDF for $a$ \emph{given} that $b$
has a particular, known value to make $p(a \given b)$ (read ``the PDF
for $a$ given $b$''), it must obey the same marginalization
\begin{eqnarray}\displaystyle
1 &=& \int p(a \given b)\,\dd a
\quad ,
\end{eqnarray}
but you can \emph{absolutely never do} the integral
\begin{eqnarray}\displaystyle
\mbox{\textbf{wrong:}} & & \int p(a \given b)\,\dd b
\end{eqnarray}
because that integral would have units of $a^{-1}\,b$, which is (for
our purposes) absurd.  Despite its absurdity, this integral has been
performed many times in error in the literature of data analyses.

If you have a probability distribution for two things (``the PDF for
$a$ and $b$''), you can always factorize it into two distributions,
one for $a$, and one for $a$ given $b$ or the other way around:
\begin{eqnarray}\displaystyle
p(a, b) &=& p(a)\,p(b \given a)
\\
p(a, b) &=& p(a \given b)\,p(b)
\quad ,
\end{eqnarray}
these two factorizations, taken together lead to what is sometimes
called ``Bayes's theorem'' but is just a simple consequence of the
factorization:
\begin{eqnarray}\displaystyle
p(a \given b) &=& \frac{p(b \given a)\,p(a)}{p(b)}
\quad ,
\end{eqnarray}
where the ``divide by $p(b)$'' aspect of that gives many philosophers
and mathematicians the chills (though certainly not me).\note{Division
  by zero is a huge danger---in principle---when applying Bayes's
  theorem.  In practice, if there is support for the model in your
  data, or support for the data in your model, you don't hit any
  zeros.}  Conditional probabilities factor just the same as
unconditional ones (and many will tell you that there is no such thing
as an unconditional probability\note{There are no unconditional
  probabilities!  This is because whenever \emph{in practice} you
  calculate a probability or a PDF, you are always making strong
  assumptions.  Your probabilities are all conditioned on these
  assumptions.}); they factor like this:
\begin{eqnarray}\displaystyle
p(a, b \given c) &=& p(a \given c)\,p(b \given a, c)
\\
p(a, b \given c) &=& p(a \given b, c)\,p(b \given c)
\\
p(a \given b, c) &=& \frac{p(b \given a, c)\,p(a \given c)}{p(b \given c)}
\quad ,
\end{eqnarray}
where the condition $c$ must be carried through all the terms; the
whole right-hand side must be conditioned on $c$ if the left-hand side
is.  Again, there was Bayes's theorem, and you can see its role in
conversions of one kind of conditional probability into another.  For
technical reasons, I usually write Bayes's theorem like this:
\begin{eqnarray}\displaystyle
p(a \given b, c) &=& \frac{1}{Z}\,p(b \given a, c)\,p(a \given c)
\\
Z &\equiv& \int p(b \given a, c)\,p(a \given c)\,\dd a
\quad .
\end{eqnarray}

Here are things you \emph{can't} do:
\begin{eqnarray}\displaystyle
\mbox{\textbf{wrong:}} & & p(a \given b, c)\,p(b \given a, c)
\\
\mbox{\textbf{wrong:}} & & p(a \given b, c)\,p(a \given c)
\quad;
\end{eqnarray}
the first over-conditions (it is not a factorization of anything
possible) and the second has units of $a^{-2}$, which is absurd (for
our purposes).  Know these and \emph{don't do them}.

``Measure theory'' (for me, anyway\note{Have you noticed that I am
  \emph{not} a mathematician?}) is the theory of things in which you
can do integrals.  You can ``integrate out'' variables you want to get
rid of (or, in what follows, \emph{not} infer) by integrals that look
like
\begin{eqnarray}\displaystyle
p(a \given c) &=& \int p(a \given b)\,p(b \given c)\,\dd b
\\
p(a \given c) &=& \int p(a \given b, c)\,p(b \given c)\,\dd b
\quad ,
\end{eqnarray}
where again the integrals go over the entire domain of $b$ in each
case.  Both of these equations are natural consequences of the things
written above and dimensional analysis.  Recall that because $b$ is
some kind of arbitrary, possibly very high-dimensional mathematical
object, these integrals can be extremely daunting in practice (see
below).

In rare cases, you can get factorizations that look like this:
\begin{eqnarray}\displaystyle
p(a, b \given c) &=& p(a \given c)\,p(b \given c)
\quad ;
\end{eqnarray}
this factorization doesn't have the PDF for $a$ depend on $b$ or vice
versa.  When this happens---and it is rare---it says that $a$ and $b$
are ``independent'' (at least conditional on $c$).\note{The word
  ``independent'' has many meanings in different contexts of
  mathematics and probability; I will avoid it in what follows, except
  in the ``iid'' or ``independent and identically distributed''
  context.  I prefer the word ``separable'' for this situation.}  In
many cases of data analysis, in models of data sets, we often have a
large number of data $a_n$, indexed by $n$, each of which is not only
independent in this sense, but also drawn from the same distribution
function.  Data of this form are called ``independent and identically
distributed'' or ``iid'' in the literature.  If you have a set of $N$
iid data $a_n$, each drawn from a probability distribution $p(a_n
\given c)$, then the probability of the full data set is simply the
product of the individual data-point probabilities:
\begin{eqnarray}\displaystyle
p(\setofall{a_n}{n=1}{N} \given c) &=& \prod_{n=1}^N p(a_n \given c)
\quad ;
\end{eqnarray}
this is really the definition, in some sense, of ``iid''.

One last point: The terminology used above \emph{enormously overloads}
the symbol $p(\cdot)$.  That is, we are using, in each line of this
discussion, the function $p(\cdot)$ to mean something different; it's
meaning is set by the letters used in its arguments.  That is a
nomenclatural abomination.\note{Serious, non-ambiguous mathematicians
  often distinguish between the name of the variable and the name of a
  draw from the probability distribution for the variable, and then
  they can write things like $p_{A|BC}(a \given b, c)$ to distinguish
  the functions.  That seems like much better practice and we should
  probably all adopt something like it.}  I apologize, but it is so
standard in our business I won't change.

\section{Posterior probabilities are personal.}

The Bayesian can produce numbers that are \emph{per unit volume
  in parameter space} whereas the frequentist can only produce numbers
that are \emph{per unit volume in data space}.  Different units
therefore different meanings therefore different capabilities.

At the end of this section I should give the example of object class
probabilities.  If you publish posterior probabilities, people with
different prior information \emph{won't be able to use them}, whereas
if you publish likelihoods, anyone can use them, frequentist or
Bayesian, and in the latter case no matter what their priors.

\section{Marginalization}

Why is marginalization extremely valuable in many contexts?  Why is it
impossible for frequentists?

\section{Regularization}

How does the prior help you when your data are bad or indecisive on
some points of interest?

\section{Don't make a decision you don't have to!}

If you look at your likelihood, it almost always has support over a
significant range in the parameters you care about.  That means that
you cannot deliver a single value of that parameter to your readers.
So don't!

\section{How to decide?}

Even despite everything written above, sometimes you are forced by
circumstances out of your control to deliver a single answer.  For an
example from my own research: You might not know with great certainty
which of the objects in your telescope field of view are the kinds of
quasars you care about, but you have to drill holes in an aluminum
plate to position fiber optics for spectroscopy.  That is, you have to
deliver instructions to a milling machine that will perform the
irreversible step of cutting metal, even though you only have
probabilistic information upon which to build these instructions.
Sometimes you really do have to \emph{decide}.\note{In my experience,
  machinists who cut metal do not appreciate being given probabilistic
  plans; it is not even clear what that would mean.  Here's a shot:
  ``Please deliver to me a sampling of devices, drawn from this
  probability distribution over plans.''  Of course even that wouldn't
  help us, because we still need to decide which of the samples to
  install at the telescope on the night we in fact observe; it would
  only delay our decision-making.}

\section{Above all, publish likelihood function evaluations!}

\begin{problem}\label{prob:intrinsic}
Will there be any \problemname s in this \documentname?
\end{problem}

\clearpage
\markright{Notes}\theendnotes

\clearpage
\begin{thebibliography}{}\markright{References}
\bibitem[Jaynes(2003)]{jaynes}
  Jaynes,~E.~T., 2003,
  \textit{Probability theory:\ The logic of science} (Cambridge University Press)
\bibitem[Mackay(2003)]{mackay}
  Mackay,~D.~J.~C., 2003,
  \textit{Information theory, inference, and learning algorithms} (Cambridge University Press)
\bibitem[Press \etal(2007)]{press}
  Press,~W.~H., Teukolsky,~S.~A., Vetterling,~W.~T., \& Flannery,~B.~P., 2007,
  \textit{Numerical recipes:\ The art of scientific computing} (Cambridge University Press)
\bibitem[Sivia \& Skilling(2006)]{sivia}
  Sivia,~D.~S. \& Skilling,~J., 2006,
  \textit{Data analysis:\ A Bayesian tutorial} (Oxford University Press)
\end{thebibliography}

\end{document}
